Regression: Linear models, ordinary least squares, ridge regression, LASSO, Gaussian
Processes regression.

### 1. Linear Models
Linear models predict a dependent variable using a straight-line relationship with one or more independent variables. It's like drawing a line that best fits the data points.

### 2. Ordinary Least Squares (OLS)
OLS is the most common method for fitting linear models. It finds the best-fitting line by minimizing the differences between the observed values and the values predicted by the line.

### 3. Ridge Regression
Ridge regression is used when there are many correlated independent variables. It modifies OLS by adding a penalty to the size of the coefficients to prevent overfitting, helping to manage multicollinearity.

### 4. LASSO (Least Absolute Shrinkage and Selection Operator)
LASSO is similar to ridge regression but uses a different penalty that can shrink some coefficients to zero. This means LASSO can be used to select important features by removing the less important ones.

### 5. Gaussian Processes Regression (GPR)
GPR is a non-linear and probabilistic approach that models the data with a flexible curve instead of a straight line. It not only predicts the values but also gives a measure of uncertainty for those predictions, making it useful for complex datasets.